{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46bVHzFjI9tn"
   },
   "outputs": [],
   "source": [
    "# step 1 run this cell to import the library and access the gpt api\n",
    "import json\n",
    "import re\n",
    "import faiss\n",
    "import torch\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "# ----------------------- SETUP -----------------------\n",
    "API_KEY = \"\"\n",
    "ENDPOINT = \"\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": API_KEY,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_oUmRQwWJDyt"
   },
   "outputs": [],
   "source": [
    "# step3 to call the gpt api\n",
    "def get_response(prompt):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": API_KEY,\n",
    "    }\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 1600\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(ENDPOINT, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "respone = get_response('i want ot go to naintial with my family for a vacation, suggest some agents who can help me book my trip. which local search keyword should I search on justdial for this query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For planning a trip to Nainital with your family, you can search for travel agents or tour operators who specialize in family vacations or hill station trips. On Justdial, you can use the following local search keywords to find suitable agents:\n",
      "\n",
      "1. \"Travel agents for Nainital\"\n",
      "2. \"Tour operators for Nainital\"\n",
      "3. \"Family vacation packages Nainital\"\n",
      "4. \"Nainital trip planner\"\n",
      "5. \"Nainital holiday packages\"\n",
      "6. \"Nainital travel agents\"\n",
      "7. \"Nainital tourism services\"\n",
      "\n",
      "By using these keywords, you should be able to find several travel agents and tour operators who can assist you in planning your trip to Nainital. Make sure to check reviews and compare packages to find the best option for your family.\n"
     ]
    }
   ],
   "source": [
    "print(respone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gAiTot-5bnQE"
   },
   "outputs": [],
   "source": [
    "# step4 prompt 1\n",
    "def prompt1(history_conversation , original_input):\n",
    "    history_text = \"\"\n",
    "    for i, (question, reply) in enumerate(history_conversation.items(), start=1):\n",
    "        history_text += f\"{i}. You asked: {question}\\n   User replied: {reply}\\n\"\n",
    "    # print(history_text)\n",
    "    prompt2 = f\"\"\"\n",
    "    You are an intelligent assistant helping Indian users find the right local service or business. Your job is to extract details from the user’s query in the exact sequence:\n",
    "    User who initially entered this query: \"{original_input}\"\n",
    "    The following clarifications have already taken place:{history_text}\n",
    "    Follow the steps in the sequential manner. Do not fill the value of one field into another, e.g., do not use area to infer city. If something is missing, ask the related clarification question until it's confirmed, and then proceed to the next step.\n",
    "    you must accurately extract three details:\n",
    "    -Step 1 – Category Extraction (LLM Instruction):\n",
    "    Extract the most suitable and generalized service, product, or business type from the user query.\n",
    "    Normalize the query: convert Hindi, Hinglish, or misspelled English into correct English.\n",
    "    Extracted category should be generalizing the category so it represents the broad need instead of a narrow subtype.\n",
    "    Expand the output into a clear explanatory phrase of at least five words. Example: “AC Repair Shop (where air conditioners get repaired)”.\n",
    "    If the query implies a category (e.g., “I want to travel to Mumbai”), deduce the most probable service types (bus booking, train tickets, flights, taxis) and select the closest generalized match instead of open-ended questioning.\n",
    "    If ambiguity remains, ask only one clarifying question with limited options (max 3–4).\n",
    "    If the query cannot be mapped to any valid service/business type, politely request the user to rephrase or provide more context.\n",
    "    Do not proceed to Step 2 until Category is confirmed.\n",
    "    After confirmation please also confirm the city and area.\n",
    "    -Step 2 – City Extraction (Second Priority): The city in India where the service is required. If no city is provided, ask for it.\n",
    "    If travel-related query like 'I want to travel to Mumbai', ask 'From which city do you want to travel to Mumbai?'.\n",
    "    If multiple cities are mentioned:\n",
    "      For travel queries → determine starting city like if user query is I want to travel to kanpur from mumbai then city shoulb be mumbai;\n",
    "      For service queries → determine the service location city in which user want the service.\n",
    "    If the location is a locality that can be confidently mapped to a city, confirm with the user.\n",
    "    If the city is outside India, respond: 'Sorry for the inconvenience, but our services are currently available only in India.\n",
    "    Could you please share the name of an Indian city where you would like to request this service? I can help you with that.'\n",
    "    -Do not proceed to Step 3 until City is confirmed.\n",
    "    Step 3 – Area Extraction (Final Priority):\n",
    "    The locality, neighbourhood, colony, or smaller part of the city where they want the service. If only a city is provided, ask 'Which area in <city> are you searching in?'.\n",
    "    The area should not be the same as the city.\n",
    "    When the extracted area does not exist in the given city, use a similarity check to find and return the closest matching area from that city\n",
    "    If the area is written in Hindi, Hinglish, or misspelled English, convert it to correct English.\n",
    "    If area seems invalid or mismatched, ask the user to provide a correct locality.\n",
    "    - If all three details (category, area, city) are confidently identified and specific and there is no missing value and all value is filled  then only return in this format:\n",
    "      Return only this JSON format (no explanation text):\n",
    "          {{\"category\": \"category_name\", \"area\": \"area_name\", \"city\": \"city_name\"}}\n",
    "    If any detail is missing or unclear, output a direct question to get that detail.\n",
    "    Examples: 'Are you looking for a train ticket agent, bus booking, or flight booking?', 'Could you please specify the city where you need this service?', 'Which area in Delhi are you searching in?'.\n",
    "    Special Handling / Edge Cases:\n",
    "    Travel Queries → Always ask both origin and destination if unclear, plus service type. Event-based Queries (e.g., 'Doctor near me') → Ask for both city and area.\n",
    "    Multiple Locations → Determine service city vs. starting point (travel).\n",
    "    Non-service Queries → Politely ask them to rephrase in terms of a local business/service. \"\"\"\n",
    "    return prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YA3y4F3hJeux"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e3Q_2AhHJi4U"
   },
   "outputs": [],
   "source": [
    "#step5 Prompt 2 to handle the threshold\n",
    "def prompt2(history_conversation, cat, area_query, threshold_cat, threshold_area, cat1, area):\n",
    "    # Build history text from past conversation\n",
    "    history_text = \"\"\n",
    "    for i, (question, reply) in enumerate(history_conversation.items(), start=1):\n",
    "        history_text += f\"{i}. You asked: {question}\\n   User replied: {reply}\\n\"\n",
    "\n",
    "    # Build cat_text and area_text based on the categories and areas provided\n",
    "    cat_text = \"\"\n",
    "    for i, category in enumerate(cat1, start=1):\n",
    "        cat_text += f\"{i}. {category}\\n\"\n",
    "\n",
    "    area_text = \"\"\n",
    "    for i, location in enumerate(area, start=1):\n",
    "        area_text += f\"{i}. {location}\\n\"\n",
    "\n",
    "    # Construct the main prompt\n",
    "    prompt2 = f\"\"\"\n",
    "You are assisting a user in identifying a local business category and area based on their query.\n",
    "Here is the conversation history:\n",
    "{history_text}\n",
    "From the initial understanding:\n",
    "- **Category**: \"{cat}\"\n",
    "- **Area**: \"{area_query}\"\n",
    "After comparing with our internal database using FAISS similarity search:\n",
    "- **Category similarity score**: {threshold_cat}\n",
    "- **Area similarity score**: {threshold_area}\n",
    "\n",
    "The threshold for category or area is below our confidence level of 0.8 or 0.9 , indicating that the provided information may be **vague**, **uncommon**, **misspelled**, or **ambiguous**.\n",
    "Action Required:\n",
    "- If **Category similarity score** score is below 0.8: Provide the top similar categories from the database, specifically using the `cat1` column (which contains potential categories from the database) and ask for clarification. Here are some similar categories:\n",
    "{cat_text}\n",
    "\n",
    "- If **Area similarity score** score is below 0.9: Provide the top similar areas from the database, specifically using the `area` column (which contains potential areas from the database) and ask for clarification. Here are some similar areas:\n",
    "{area_text}\n",
    "\n",
    "- Prioritize the item with the **lower threshold** (either category or area) for clarification.\n",
    "\n",
    "Your task:\n",
    "Generate **one simple follow-up question** based on the following:\n",
    "- If the category is unclear: \"Are you looking for [specific example of categories from {cat_text}]?\"\n",
    "- If the area is unclear: \"Could you please tell me which locality or area within {area_text} you're searching in?\"\n",
    "- If both are unclear: \"Could you clarify both the exact service you're looking for and the area within your city?\"\n",
    "\n",
    "Special Cases:\n",
    "- Multiple locations mentioned: Ask the user to clarify the service location vs. starting point if related to travel.\n",
    "- Ambiguous categories (e.g., “repair”, “booking”, “printing”): Ask for more specifics on the type.\n",
    "- Non-service-related queries: Politely ask the user to rephrase or clarify their needs.\n",
    "\n",
    "Return only the **follow-up question**. Do not include explanations or additional information.\n",
    "\"\"\"\n",
    "    return prompt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4eN0Iq7fUaEg"
   },
   "outputs": [],
   "source": [
    "# step6\n",
    "def prompt_follow1(categories , cat_org):\n",
    "    category_text = \"\"\n",
    "    for cat in categories :\n",
    "        category_text += f\"{cat} , \"\n",
    "    # print(history_text)\n",
    "    prompt2 = f\"\"\"\n",
    "    You are an intelligent assistant helping Indian users find the right local service or business.\n",
    "    This is the {cat_org} which is extracted from the usery queries.\n",
    "    These are the Link categories {category_text}\n",
    "    Your Task to ask the follow up question regarding the Link category.\n",
    "    Example Are you also interesting in {category_text}?\n",
    "    Use the Example as context do not return the question which look like same as the example.\n",
    "    Give the follow up question grammarily correct . and simple ensure Link categories be in the question.\n",
    "     \"\"\"\n",
    "    return prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in c:\\programdata\\anaconda3\\lib\\site-packages (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from fastparquet) (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from fastparquet) (2.3.2)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.11.0-cp313-cp313-win_amd64.whl.metadata (681 bytes)\n",
      "Requirement already satisfied: fsspec in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from fastparquet) (2025.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10176189\\documents\\whatshapp_bot_final\\chatenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
      "Downloading fastparquet-2024.11.0-cp313-cp313-win_amd64.whl (673 kB)\n",
      "   ---------------------------------------- 0.0/673.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 673.3/673.3 kB 7.5 MB/s  0:00:00\n",
      "Downloading cramjam-2.11.0-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 10.5 MB/s  0:00:00\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "\n",
      "   -------------------- ------------------- 1/2 [fastparquet]\n",
      "   ---------------------------------------- 2/2 [fastparquet]\n",
      "\n",
      "Successfully installed cramjam-2.11.0 fastparquet-2024.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "De1-4NDIJmTc"
   },
   "outputs": [],
   "source": [
    "# search_runtime.py\n",
    "# ensure to install transformers torch faiss-cpu pandas numpy pyarrow\n",
    "# To import the embeddeing model\n",
    "# step7\n",
    "\n",
    "# Change the path of directory.\n",
    "# ART_DIR = \"/content/drive/MyDrive/justdial for whatsapp\"\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
    "\n",
    "# Load metadata\n",
    "# df_cat = pd.read_parquet(f\"df_cat.parquet\")\n",
    "df_cat = pd.read_parquet(\"df_cat.parquet\", engine=\"fastparquet\")\n",
    "df_area = pd.read_parquet(\"df_area1.parquet\" , engine=\"fastparquet\")\n",
    "\n",
    "# Load FAISS indexes\n",
    "index_cat = faiss.read_index(f\"index_cat.faiss\")\n",
    "index_area = faiss.read_index(f\"index_area1.faiss\")\n",
    "\n",
    "# Load model for query encoding\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "mdl = AutoModel.from_pretrained(MODEL_NAME).to(device).eval()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def e5_encode(texts, is_query=False, batch_size=64, max_length=64):\n",
    "    prefix = \"query: \" if is_query else \"passage: \"\n",
    "    vecs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = [prefix + str(t).strip() for t in texts[i:i+batch_size]]\n",
    "        enc = tok(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        out = mdl(**enc).last_hidden_state[:, 0]\n",
    "        out = torch.nn.functional.normalize(out, p=2, dim=1)\n",
    "        vecs.append(out.cpu().numpy().astype(\"float32\"))\n",
    "    return np.vstack(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_category(text):\n",
    "    # Split into main category and explanation\n",
    "    if \"(\" in text and \")\" in text:\n",
    "        main, explanation = text.split(\"(\", 1)\n",
    "        main = main.strip()\n",
    "        explanation = \"(\" + explanation.strip()\n",
    "        return f\"Main category is {main} and this is category explanation {explanation} \"\n",
    "    else:\n",
    "        # If no explanation given\n",
    "        return f\"Main category is {text.strip()}\"\n",
    "# Example\n",
    "# category = \"Tent Rental Services (where tents are rented for events)\"\n",
    "# output = format_category(category)\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "PvIMSs8-JpUb"
   },
   "outputs": [],
   "source": [
    "# step 8\n",
    "# Search algorithm for the embedding model\n",
    "def _safe_cols(df: pd.DataFrame, wanted_cols: list) -> list:\n",
    "    return [c for c in wanted_cols if c in df.columns]\n",
    "\n",
    "def search_categories(user_query: str, top_k: int = 5) -> pd.DataFrame:\n",
    "    user_query = format_category(user_query)\n",
    "    qv = e5_encode([user_query], is_query=True)\n",
    "    D, I = index_cat.search(qv, top_k)\n",
    "    res = df_cat1.iloc[I[0]].copy()\n",
    "    res[\"cosine_similarity\"] = D[0]\n",
    "    cols = _safe_cols(res, ['national_catid', 'categroy_name' , 'embedding'])\n",
    "    return res[cols + [\"cosine_similarity\"]] , qv\n",
    "\n",
    "def search_areas(user_query: str, top_k: int = 5) -> pd.DataFrame:\n",
    "    user_query = user_query.lower()\n",
    "    cleaned = re.sub(r\"[^\\w]\", \"\", user_query)\n",
    "    qv = e5_encode([cleaned], is_query=True)\n",
    "    D, I = index_area.search(qv, top_k)\n",
    "    res = df_area.iloc[I[0]].copy()\n",
    "    res[\"cosine_similarity\"] = D[0]\n",
    "    cols = _safe_cols(res, [\"main_area\", \"pincode\", \"city\"])\n",
    "    return res[cols + [\"cosine_similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat1 = pd.read_pickle('df_cat_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_catid</th>\n",
       "      <th>categroy_name</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10050521</td>\n",
       "      <td>Body Massage Centres</td>\n",
       "      <td>[0.020193165, -0.011742339, -0.016831696, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11010608</td>\n",
       "      <td>Massage Centres For Men</td>\n",
       "      <td>[0.019172434, -0.0006042592, -0.029820744, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10272436</td>\n",
       "      <td>Interior Designers</td>\n",
       "      <td>[-0.005018342, 0.014741824, -0.023653127, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10076456</td>\n",
       "      <td>Car Rental</td>\n",
       "      <td>[0.026977241, 0.008907894, -0.009950297, 0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10042600</td>\n",
       "      <td>Beauty Spas</td>\n",
       "      <td>[0.015548817, -0.0037554502, -0.023473088, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  national_catid            categroy_name  \\\n",
       "0       10050521     Body Massage Centres   \n",
       "1       11010608  Massage Centres For Men   \n",
       "2       10272436       Interior Designers   \n",
       "3       10076456               Car Rental   \n",
       "4       10042600              Beauty Spas   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.020193165, -0.011742339, -0.016831696, -0.0...  \n",
       "1  [0.019172434, -0.0006042592, -0.029820744, -0....  \n",
       "2  [-0.005018342, 0.014741824, -0.023653127, 0.00...  \n",
       "3  [0.026977241, 0.008907894, -0.009950297, 0.018...  \n",
       "4  [0.015548817, -0.0037554502, -0.023473088, 0.0...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df , qv = search_categories('chemists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_catid</th>\n",
       "      <th>categroy_name</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>10502663</td>\n",
       "      <td>Tutorials For Class XII Chemistry</td>\n",
       "      <td>[-0.016723225, 0.023238415, -0.022944383, 0.03...</td>\n",
       "      <td>0.884532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>10096237</td>\n",
       "      <td>Chemists</td>\n",
       "      <td>[-0.016057754, 0.01176591, -0.030365767, 0.001...</td>\n",
       "      <td>0.883691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>10623805</td>\n",
       "      <td>Tutorials For Class XI Chemistry</td>\n",
       "      <td>[-0.018147292, 0.024671588, -0.025833273, 0.02...</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>10502611</td>\n",
       "      <td>Chemistry Tutorials</td>\n",
       "      <td>[-0.006465669, 0.003201086, -0.019049563, 0.02...</td>\n",
       "      <td>0.879046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6764</th>\n",
       "      <td>11575237</td>\n",
       "      <td>Tutorials For Neet Chemistry</td>\n",
       "      <td>[-0.015928844, 0.01483429, -0.012638513, 0.016...</td>\n",
       "      <td>0.874187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     national_catid                      categroy_name  \\\n",
       "1950       10502663  Tutorials For Class XII Chemistry   \n",
       "262        10096237                           Chemists   \n",
       "3685       10623805   Tutorials For Class XI Chemistry   \n",
       "1392       10502611                Chemistry Tutorials   \n",
       "6764       11575237       Tutorials For Neet Chemistry   \n",
       "\n",
       "                                              embedding  cosine_similarity  \n",
       "1950  [-0.016723225, 0.023238415, -0.022944383, 0.03...           0.884532  \n",
       "262   [-0.016057754, 0.01176591, -0.030365767, 0.001...           0.883691  \n",
       "3685  [-0.018147292, 0.024671588, -0.025833273, 0.02...           0.881250  \n",
       "1392  [-0.006465669, 0.003201086, -0.019049563, 0.02...           0.879046  \n",
       "6764  [-0.015928844, 0.01483429, -0.012638513, 0.016...           0.874187  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xTH1tjbVJrjl"
   },
   "outputs": [],
   "source": [
    "# step 9\n",
    "def extract_json(response):\n",
    "    match = re.search(r'\\{.*?\\}', response, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group())\n",
    "        except:\n",
    "            return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HNUIzofGJtmT"
   },
   "outputs": [],
   "source": [
    "#  step 10\n",
    "\n",
    "def extract_category(text):\n",
    "    # Use a regex pattern to capture everything before the first '('\n",
    "    match = re.match(r\"^([^(]+)\", text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None  # Return None if no match is found\n",
    "\n",
    "  # Output: Gym Service\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3qNPpHKUVSnI"
   },
   "outputs": [],
   "source": [
    "  # step 11\n",
    "  not_field = {\n",
    "    \"N/A\", \"NA\", \"n/a\", \"na\", \"null\", \"NULL\", \"\", \"-\", \"none\", \"None\",\n",
    "    \"not available\", \"not applicable\", \"unspecified\", \"unknown\",\n",
    "    \"not_available\", \"not_applicable\", \"not_provided\", \"not_supplied\",\n",
    "    \"not_captured\", \"not_recorded\", \"not_collected\", \"not_entered\",\n",
    "    \"not_disclosed\", \"not_shared\", \"not_furnished\", \"not_known\",\n",
    "    \"not_identified\", \"not_determined\", \"undetermined\", \"missing\",\n",
    "    \"missing_value\", \"missing_data\", \"no_data\", \"no_response\",\n",
    "    \"no_answer\", \"no_result\", \"empty_value\", \"blank_value\",\n",
    "    \"null_value\", \"withheld\", \"redacted\", \"confidential\",\n",
    "    \"pii_removed\", \"policy_restricted\", \"compliance_restricted\",\n",
    "    \"restricted\", \"forbidden\", \"blocked\", \"safety_blocked\",\n",
    "    \"content_blocked\", \"ambiguous\", \"unclear\", \"vague\",\n",
    "    \"needs_clarification\", \"insufficient_context\", \"insufficient_detail\",\n",
    "    \"low_confidence\",\"not provided\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8BlK8xQAGvoF"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # keep only letters, numbers, spaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "B1Vvzo_pGpMg"
   },
   "outputs": [],
   "source": [
    "# step 12\n",
    "# main function handle all conversation and follow up question\n",
    "def main_function(response, area_1=\"\", city_1=\"\" , start=False):\n",
    "    first_user = input(f\"Assitant : {response}\\nUser : \")\n",
    "    history_conversation = {}\n",
    "    a = response\n",
    "    a = a.lower()\n",
    "    if start == True:\n",
    "      first_user +=f\"area is {area_1} , and city is {city_1} Please used this only as area and city not ask the question related area and city but ask question on categories for clarity\"\n",
    "    history_conversation[a] = first_user.lower()\n",
    "    threshold_cat = 0\n",
    "    threshold_area = 0\n",
    "    cnt = 0\n",
    "    df_cat_res = pd.DataFrame()\n",
    "    df_area_res = pd.DataFrame()\n",
    "    cat = ''\n",
    "    area = ''\n",
    "    city = ''\n",
    "    # Adjusted threshold condition for better clarity\n",
    "    while ((threshold_cat < 0.7 or threshold_area < 0.75) and cnt < 7):\n",
    "        # Assuming prompt_fun1 generates the query for extracting data\n",
    "        prompt2 = prompt1(history_conversation, first_user)\n",
    "        response = get_response(prompt1)\n",
    "        parsed = extract_json(response)\n",
    "\n",
    "        if parsed:\n",
    "            cat = parsed.get(\"category\")\n",
    "            area = parsed.get(\"area\")\n",
    "            city = parsed.get(\"city\")\n",
    "\n",
    "            # If any of the parsed data is missing, skip and ask for more clarification\n",
    "            cat_clean = preprocess_text(cat)\n",
    "            area_clean = preprocess_text(area)\n",
    "            city_clean = preprocess_text(city)\n",
    "\n",
    "            # Preprocess not_field set\n",
    "            not_field_clean = {preprocess_text(x) for x in not_field}\n",
    "\n",
    "            # Now check\n",
    "            if (not cat_clean or cat_clean in not_field_clean or\n",
    "                not area_clean or area_clean in not_field_clean or\n",
    "                not city_clean or city_clean in not_field_clean):\n",
    "\n",
    "                missing_data = []\n",
    "                if not cat_clean or cat_clean in not_field_clean:\n",
    "                    missing_data.append(\"Category\")\n",
    "                if not area_clean or area_clean in not_field_clean:\n",
    "                    missing_data.append(\"Area\")\n",
    "                if not city_clean or city_clean in not_field_clean:\n",
    "                    missing_data.append(\"City\")\n",
    "                missing_str = ', '.join(missing_data)\n",
    "                response = f\"We are unable to get your {missing_str}, Please specify it with city.\"\n",
    "                user_input = input(f\"Assitant : {response}\\nUser : \")\n",
    "                history_conversation[response] = user_input\n",
    "                cnt += 1\n",
    "                continue   # Re-run the loop for further input\n",
    "            # Assuming these functions return dataframes with cosine similarity values\n",
    "            df_cat_res = search_categories(cat, top_k=5)\n",
    "            area_query = f\"{area} {city}\"\n",
    "            # print(area_query)\n",
    "            df_area_res = search_areas(area_query, top_k=5)\n",
    "\n",
    "            # Check if DataFrames are empty or invalid\n",
    "            if not df_cat_res.empty and not df_area_res.empty:\n",
    "                threshold_cat = df_cat_res['cosine_similarity'].max()\n",
    "                threshold_area = df_area_res['cosine_similarity'].max()\n",
    "\n",
    "            print(f\"Gpt Extracted:\\nCategory: {cat}\\nArea: {area}\\nCity: {city}\")\n",
    "\n",
    "            if threshold_cat < 0.7 or threshold_area < 0.75:\n",
    "                # Assuming prompt_fun4 is designed to generate a clarification question\n",
    "                # print('prompt2')\n",
    "                prompt_question = prompt2(history_conversation, cat, area_query, threshold_cat, threshold_area, df_cat_res['categroy_name'], df_area_res[['main_area', 'city']])\n",
    "                response = get_response(prompt_question)\n",
    "                cnt += 1\n",
    "                user = input(f\"Assitant : {response}\\nUser : \")\n",
    "                history_conversation[response] = user\n",
    "                continue\n",
    "            else:\n",
    "                categories = df_cat_res[df_cat_res['cosine_similarity'] == df_cat_res['cosine_similarity'].max()]['categroy_name'].iloc[0]\n",
    "                national_catid = df_cat_res[df_cat_res['cosine_similarity'] == df_cat_res['cosine_similarity'].max()]['national_catid'].iloc[0]\n",
    "                area_main= df_area_res[df_area_res['cosine_similarity'] == df_area_res['cosine_similarity'].max()]['main_area'].iloc[0]\n",
    "                city_name= df_area_res[df_area_res['cosine_similarity'] == df_area_res['cosine_similarity'].max()]['city'].iloc[0]\n",
    "                pincode = df_area_res[df_area_res['cosine_similarity'] == df_area_res['cosine_similarity'].max()]['pincode'].iloc[0]\n",
    "                output = f\"\"\"\n",
    "The most similar category with the national_catid matching the user’s query:\n",
    "national_catid : {national_catid}\n",
    "category_name : {categories}\n",
    "\n",
    "The most relevant areas based on the information provided by the user:\n",
    "Main_area : {area_main}\n",
    "Pincode : {pincode}\n",
    "City : {city}\n",
    "                \"\"\"\n",
    "                print(output)\n",
    "                # return df_cat[['national_catid', 'category_name']], df_area[df_area['city'].str.lower() == city.lower()][['main_area', 'city', 'cosine_similarity']], (cat, area, city, threshold_cat, threshold_area)\n",
    "                return national_catid , categories , city_name , pincode , area_main\n",
    "        else:\n",
    "            # Handle the case where parsing fails\n",
    "            user_input = input(f\"Assitant : {response}\\n\")\n",
    "            history_conversation[response] = user_input\n",
    "            cnt += 1\n",
    "            continue\n",
    "        cnt += 1\n",
    "    # return df_cat[['national_catid', 'category_name']], df_area[df_area['city'].str.lower() == city.lower()][['main_area', 'city', 'cosine_similarity']], (cat, area, city, threshold_cat, threshold_area)\n",
    "    categories = df_cat_res[df_cat_res['cosine_similarity'] == df_cat_res['cosine_similarity'].max()]['categroy_name'].iloc[0]\n",
    "    national_catid = df_cat_res[df_cat_res['cosine_similarity'] == df_cat_res['cosine_similarity'].max()]['national_catid'].iloc[0]\n",
    "    area_main= df_area_res[df_area_res['cosine_similarity'] == df_area_res['cosine_similarity'].max()]['main_area'].iloc[0]\n",
    "    city_name= df_area_res[df_area_res['cosine_similarity'] == df_area_res['cosine_similarity'].max()]['city'].iloc[0]\n",
    "    pincode = df_area_res[df_area_res['cosine_similarity'] == df_area_res['cosine_similarity'].max()]['pincode'].iloc[0]\n",
    "    output = f\"\"\"\n",
    "The most similar category with the national_catid matching the user’s query:\n",
    "national_catid : {national_catid}\n",
    "category_name : {categories}\n",
    "\n",
    "The most relevant areas based on the information provided by the user:\n",
    "Main_area : {area_main}\n",
    "Pincode : {pincode}\n",
    "City : {city}\n",
    "    \"\"\"\n",
    "    print(output)\n",
    "    # return df_cat[['national_catid', 'category_name']], df_area[df_area['city'].str.lower() == city.lower()][['main_area', 'city', 'cosine_similarity']], (cat, area, city, threshold_cat, threshold_area)\n",
    "    return national_catid , categories, city_name , pincode , area_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uc0mZOa1WgTg"
   },
   "outputs": [],
   "source": [
    "# step 13\n",
    "# to continue the conversation with user\n",
    "def cat_link(category: str, df):\n",
    "    # Convert both sides to lowercase for comparison\n",
    "    category_lower = category.lower()\n",
    "    df['category_name_lower'] = df['category_name'].str.lower()\n",
    "\n",
    "    # Check if the category exists\n",
    "    if category_lower in df['category_name_lower'].values:\n",
    "        # Find the corresponding immidate\n",
    "        link_cat = df.loc[df['category_name_lower'] == category_lower, 'immidate'].iloc[0]\n",
    "\n",
    "        # Get all categories with the same immidate\n",
    "        categories = df.loc[df['immidate'] == link_cat, 'category_name'].tolist()\n",
    "\n",
    "        return categories, category\n",
    "    else:\n",
    "        return [], 'END'  # No match found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def extract_business_info(api, limit=4):\n",
    "    try:\n",
    "        response = requests.get(api, timeout=60)  # disable SSL verify\n",
    "        response.raise_for_status()\n",
    "        api_response = response.json()\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"⏳ API request timed out.\")\n",
    "        return []\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"⚠️ API request failed: {e}\")\n",
    "        return []\n",
    "\n",
    "    organic_res = api_response.get(\"organic_res\", {})\n",
    "    if not isinstance(organic_res, dict):\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for i, (docid, details) in enumerate(organic_res.items()):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        if not isinstance(details, dict):\n",
    "            continue\n",
    "\n",
    "        company = details.get(\"companyname\", \"\")\n",
    "        city = details.get(\"city\", \"\")\n",
    "        area = details.get(\"area\", \"\")\n",
    "        rating = details.get(\"d_rating\" , \"\")\n",
    "        mobile = details.get(\"mobile_display\", [])\n",
    "        if isinstance(mobile, (int, float, str)): mobile = [str(mobile)] \n",
    "        elif not isinstance(mobile, list): mobile = []\n",
    "        results.append({\n",
    "            \"docid\": docid,\n",
    "            \"companyname\": company,\n",
    "            \"mobile_display\": mobile,\n",
    "            \"rating\" : rating,\n",
    "            \"area\": area,\n",
    "            \"city\": city\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text1(x):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    x = x.lower()\n",
    "    x = re.sub(r\"[^\\w]\", \"\", x)  # keep only alphanumeric + underscore\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_output(data):\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required = ['companyname', 'mobile_display', 'rating', 'area', 'city']\n",
    "    for c in required:\n",
    "        if c not in df.columns:\n",
    "            df[c] = \"\"\n",
    "\n",
    "    df = df[required].copy()\n",
    "\n",
    "    # Normalize mobile_display to a single number (first one if comma-separated)\n",
    "    def pick_first_mobile(x):\n",
    "        if isinstance(x, list):\n",
    "            # take first non-empty element; also split if that element has commas\n",
    "            for item in x:\n",
    "                s = str(item).strip()\n",
    "                if s:\n",
    "                    return s.split(\",\")[0].strip()\n",
    "            return \"\"\n",
    "        if pd.isna(x):\n",
    "            return \"\"\n",
    "        return str(x).split(\",\")[0].strip()\n",
    "\n",
    "    df['mobile_display'] = df['mobile_display'].apply(pick_first_mobile)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_api(api):\n",
    "    data = extract_business_info(api, limit=5)\n",
    "    df = format_output(data)\n",
    "\n",
    "    # Clean headers & basic formatting\n",
    "    df = df.rename(columns={\n",
    "        'companyname': 'Company',\n",
    "        'mobile_display': 'Mobile',\n",
    "        'rating': 'Rating',\n",
    "        'area': 'Area',\n",
    "        'city': 'City'\n",
    "    })[['Company', 'Mobile', 'Rating', 'Area', 'City']]\n",
    "\n",
    "    # Format Rating (keep as string, 1 decimal if numeric)\n",
    "    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce').map(\n",
    "        lambda x: f\"{x:.1f}\" if pd.notnull(x) else \"\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def pretty_print_df(df: pd.DataFrame) -> None:\n",
    "    # Try nice terminal table\n",
    "    try:\n",
    "        from tabulate import tabulate\n",
    "        print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
    "    except ImportError:\n",
    "        # Fallback: good-looking pandas print\n",
    "        with pd.option_context(\n",
    "            'display.max_colwidth', 60,\n",
    "            'display.width', 120,\n",
    "            'display.colheader_justify', 'left'\n",
    "        ):\n",
    "            print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b5qxQPhSUgHS"
   },
   "outputs": [],
   "source": [
    "# step 14\n",
    "# This final function which handle the starting and ending of conversation\n",
    "def whatshapp_chat():\n",
    "  end = False\n",
    "  # Change the path of link categories.\n",
    "  df = pd.read_excel('Documents/Whatshapp_bot_final/link_categories.xlsx')\n",
    "  response = 'How can I help you ?'\n",
    "  area = ''\n",
    "  city = ''\n",
    "  start=False\n",
    "  while end!=True:\n",
    "    try:\n",
    "      national_catid , cat_name, city_name , pincode , main_area = main_function(response , area , city , start)\n",
    "      start = True\n",
    "      city = city_name\n",
    "      area = main_area\n",
    "      city_name = clean_text1(city_name)\n",
    "      national_catid = clean_text1(national_catid) \n",
    "      api = f'http://192.168.8.12:9001/web_services/CategorySearch_universal.php?catid=&city={city_name}&area={pincode}&start=1&end=10&random1=0.61266&random2=0.34577&random3=0.00138&wap_flag=0&nearme_flag=0&nearme_latitude=&nearme_longitude=&catname=&search_option=1&product_id=&catname_search=&json=1&sort_order=&national_catid={national_catid}&onational_catid=&attribute_values=&state=&darea_flg=0&wap=2&login_mobile=9008008546&pdocid=&trace='  \n",
    "      data = search_api(api)     # assumes `api` is defined\n",
    "      pretty_print_df(data)\n",
    "      temp = input(f\"Do you want to end the conversation ? (yes/no): \\n\").lower()\n",
    "      if temp == \"yes\":\n",
    "        end = True\n",
    "        break\n",
    "      categories , cat = cat_link(cat_name , df)\n",
    "      if cat == 'END':\n",
    "        print(f'No link categories found with {cat_name}')\n",
    "        end = True\n",
    "        break\n",
    "      prompt2 = prompt_follow1(categories, cat)\n",
    "      response = get_response(prompt2)\n",
    "    except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "      end = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "awHVjF3RbXm5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Documents/Whatshapp_bot_final/link_categories.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m whatshapp_chat()\n",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m, in \u001b[0;36mwhatshapp_chat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Change the path of link categories.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocuments/Whatshapp_bot_final/link_categories.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow can I help you ?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m area \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Documents/Whatshapp_bot_final/link_categories.xlsx'"
     ]
    }
   ],
   "source": [
    "whatshapp_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqIAfTmLX0Lx",
    "outputId": "ced00b46-bc61-462e-a36b-5714f0b87744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant : How can I help you ?\n",
      "User :  My sister is getting marreid, I need people who can preapre food for the wedding\n",
      "Assitant : Could you please specify the city where you need the food preparation service for the wedding?\n",
      " Delhi\n",
      "Assitant : Could you please specify which area in Delhi are you searching for the food preparation service for the wedding?\n",
      " greater kailas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpt Extracted:\n",
      "Category: Catering Services (where food is prepared for events)\n",
      "Area: Greater Kailash\n",
      "City: Delhi\n",
      "\n",
      "The most similar category with the national_catid matching the user’s query:\n",
      "national_catid : 10083351\n",
      "category_name : Caterers For Events\n",
      "\n",
      "The most relevant areas based on the information provided by the user:\n",
      "Main_area : Greater Kailash\n",
      "Pincode : 110048\n",
      "City : Delhi\n",
      "                \n",
      "+------------------------+------------------+----------+---------------+--------+\n",
      "| Company                | Mobile           |   Rating | Area          | City   |\n",
      "+========================+==================+==========+===============+========+\n",
      "| Rtw Tikki Wala         | +(91)-9999189540 |      4.2 | Paschim Vihar | Delhi  |\n",
      "+------------------------+------------------+----------+---------------+--------+\n",
      "| Standard Caterers      | +(91)-9312404879 |      4   | Paschim Vihar | Delhi  |\n",
      "+------------------------+------------------+----------+---------------+--------+\n",
      "| Om Sai Tent & Caterers | +(91)-9818006821 |      5   | Meera Bagh    | Delhi  |\n",
      "+------------------------+------------------+----------+---------------+--------+\n",
      "| Kumar Snacks & Sweet   | +(91)-9899174223 |      3.9 | Paschim Vihar | Delhi  |\n",
      "+------------------------+------------------+----------+---------------+--------+\n",
      "| Jade's                 | +(91)-8527347455 |      4   | Paschim Vihar | Delhi  |\n",
      "+------------------------+------------------+----------+---------------+--------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to end the conversation ? (yes/no): \n",
      " yes\n"
     ]
    }
   ],
   "source": [
    "# To start the chatbot run this cel\n",
    "whatshapp_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant : How can I help you ?\n",
      "User :  i want ot go to naintial with my family for a vacation, suggest some agents who can help me book my trip\n",
      "Assitant : Are you looking for a train ticket agent, bus booking, or flight booking?\n",
      " yes\n",
      "Assitant : Could you please specify the city from which you want to travel to Nainital?\n",
      " bagalore\n",
      "Assitant : We are unable to get your Area, Please specify it with city.\n",
      "User :  peenya\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpt Extracted:\n",
      "Category: Travel Booking Agent (for planning and booking trips)\n",
      "Area: Peenya\n",
      "City: Bangalore\n",
      "\n",
      "The most similar category with the national_catid matching the user’s query:\n",
      "national_catid : 10496380\n",
      "category_name : Travel Agents\n",
      "\n",
      "The most relevant areas based on the information provided by the user:\n",
      "Main_area : Peenya\n",
      "Pincode : 560058\n",
      "City : Bangalore\n",
      "                \n",
      "+--------------------------------+------------------+----------+--------+-----------+\n",
      "| Company                        | Mobile           |   Rating | Area   | City      |\n",
      "+================================+==================+==========+========+===========+\n",
      "| Krishna Priya Tours & Travels  | +(91)-9290909992 |      5   |        | Bangalore |\n",
      "+--------------------------------+------------------+----------+--------+-----------+\n",
      "| Tour And Travels               | +(91)-9632244562 |      4.8 |        | Bangalore |\n",
      "+--------------------------------+------------------+----------+--------+-----------+\n",
      "| Sathya Sai Travels             | +(91)-9620656801 |      4.3 |        | Bangalore |\n",
      "+--------------------------------+------------------+----------+--------+-----------+\n",
      "| Easy Driver Bangalore Services |                  |      3.4 |        | Bangalore |\n",
      "+--------------------------------+------------------+----------+--------+-----------+\n",
      "| Kumar Travels                  | +(91)-6361735176 |      5   |        | Bangalore |\n",
      "+--------------------------------+------------------+----------+--------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to end the conversation ? (yes/no): \n",
      " yes\n"
     ]
    }
   ],
   "source": [
    "whatshapp_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "eIMksu45bX8R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_catid</th>\n",
       "      <th>categroy_name</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6253</th>\n",
       "      <td>10083352</td>\n",
       "      <td>Caterers For Function</td>\n",
       "      <td>0.897012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>10268601</td>\n",
       "      <td>Institutes For Catering</td>\n",
       "      <td>0.896209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>11664893</td>\n",
       "      <td>Biryani Caterers</td>\n",
       "      <td>0.892204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>10083536</td>\n",
       "      <td>Catering Kitchen Equipment Manufacturers</td>\n",
       "      <td>0.889224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>11664517</td>\n",
       "      <td>Paan Caterers</td>\n",
       "      <td>0.888467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     national_catid                             categroy_name  \\\n",
       "6253       10083352                     Caterers For Function   \n",
       "7396       10268601                   Institutes For Catering   \n",
       "1398       11664893                          Biryani Caterers   \n",
       "5163       10083536  Catering Kitchen Equipment Manufacturers   \n",
       "7987       11664517                             Paan Caterers   \n",
       "\n",
       "      cosine_similarity  \n",
       "6253           0.897012  \n",
       "7396           0.896209  \n",
       "1398           0.892204  \n",
       "5163           0.889224  \n",
       "7987           0.888467  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_categories(' Catering ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLoTX3qFZAwA"
   },
   "outputs": [],
   "source": [
    "# main_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpWSz72Vhkfj",
    "outputId": "aa3850fe-ad91-4bed-d582-dd1c93d6e562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I help you?\n",
      "I am looking for gym which is open for 24 hr\n",
      "Could you please specify the city where you need this service?\n",
      "bangalore\n",
      "We are unable to get your Area, Please specify it with city.\n",
      "mg road\n",
      "Extracted:\n",
      "Category: 24 Hour Gym Facility\n",
      "Area: mg road\n",
      "City: bangalore\n",
      "Threshold Cat: 0.8868585824966431\n",
      "Threshold Area: 0.9246256351470947\n",
      "\n",
      "The most similar category with the national_catid matching the user’s query:\n",
      "national_catid : 10208976\n",
      "category_name : Fitness Centres\n",
      "\n",
      "The most relevant areas based on the information provided by the user:\n",
      "Main_area : M G Road\n",
      "Pincode : 560001\n",
      "City : Bangalore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# main_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paLyTm3Rhet1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vU-ElxT7J5t3",
    "outputId": "da06c58c-246b-4362-de63-b2e7be22c52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. You asked: how can i help you ?\n",
      "   User replied: mujhe mere sandas ka nall theek karwana hai, paani dheeme dheeme aa raha hai. maza nahi aaya.\n",
      "\n",
      "1. You asked: how can i help you ?\n",
      "   User replied: mujhe mere sandas ka nall theek karwana hai, paani dheeme dheeme aa raha hai. maza nahi aaya.\n",
      "2. You asked: The extracted category from your query is: \"Plumbing Service (where plumbing issues like leaks and slow drainage are fixed)\".\n",
      "\n",
      "Could you please specify the city where you need this service?\n",
      "   User replied: yamuna paar\n",
      "\n",
      "1. You asked: how can i help you ?\n",
      "   User replied: mujhe mere sandas ka nall theek karwana hai, paani dheeme dheeme aa raha hai. maza nahi aaya.\n",
      "2. You asked: The extracted category from your query is: \"Plumbing Service (where plumbing issues like leaks and slow drainage are fixed)\".\n",
      "\n",
      "Could you please specify the city where you need this service?\n",
      "   User replied: yamuna paar\n",
      "3. You asked: Could you please confirm the area in Yamuna Paar where you need this plumbing service?\n",
      "   User replied: ghaziabad\n",
      "\n",
      "Extracted:\n",
      "Category: Plumbing Service\n",
      "Area: Ghaziabad\n",
      "City: Yamuna Paar\n",
      "Threshold Cat: 0.9112212657928467\n",
      "Threshold Area: 0.889767050743103\n",
      "\n",
      "The most similar category with the national_catid matching the user’s query:\n",
      "national_catid : 10378056\n",
      "category_name : Plumbing Contractors\n",
      "\n",
      "The most relevant areas based on the information provided by the user:\n",
      "Main_area : Ghati Pada\n",
      "Pincode : 400080\n",
      "City : Mumbai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(Telegram_bot2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3Tjami5SQ71",
    "outputId": "ed23dd6f-0c36-4aac-da18-47dcf41b662a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I help you?\n",
      "bhuk lag rahi hai\n",
      "1. You asked: how can i help you ?\n",
      "   User replied: bhuk lag rahi hai\n",
      "\n",
      "Could you please specify the city where you need this service?\n",
      "delhi\n",
      "1. You asked: how can i help you ?\n",
      "   User replied: bhuk lag rahi hai\n",
      "2. You asked: Could you please specify the city where you need this service?\n",
      "   User replied: delhi\n",
      "\n",
      "Are you looking for a restaurant, street food, or delivery service?\n",
      "jaldi jo mile\n",
      "1. You asked: how can i help you ?\n",
      "   User replied: bhuk lag rahi hai\n",
      "2. You asked: Could you please specify the city where you need this service?\n",
      "   User replied: delhi\n",
      "3. You asked: Are you looking for a restaurant, street food, or delivery service?\n",
      "   User replied: jaldi jo mile\n",
      "\n",
      "Extracted:\n",
      "Category: Food Delivery Service\n",
      "Area: N/A\n",
      "City: Delhi\n",
      "Threshold Cat: 0.9153370261192322\n",
      "Threshold Area: 0.9073697328567505\n",
      "\n",
      "The most similar category with the national_catid matching the user’s query:\n",
      "national_catid : 11960441\n",
      "category_name : Fast Food Delivery Services\n",
      "\n",
      "The most relevant areas based on the information provided by the user:\n",
      "Main_area : Nawada\n",
      "Pincode : 110059\n",
      "City : Delhi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(Telegram_bot2())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
