{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b37ed48-5179-476f-955c-cd28761af903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081b51c1-e06c-4695-967f-e34033c23a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot = pd.read_excel('df_cat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430b1a7b-b722-4284-9d6c-9e483315d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10775 entries, 0 to 10774\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Unnamed: 0      10775 non-null  int64 \n",
      " 1   national_catid  10775 non-null  int64 \n",
      " 2   categroy_name   10775 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 252.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_hot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b8cce05-5c74-42ec-bb21-8ca41505eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot = df_hot.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34cbf59a-c775-4567-9b56-092462d93709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10775 entries, 0 to 10774\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   national_catid  10775 non-null  int64 \n",
      " 1   category_name   10775 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 168.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_hot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f466f61-f91e-45eb-81bf-e359187760f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot.to_excel('gpt_5k.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e8fe8e-1ec6-45ac-b7f2-88371cf0bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot.rename(columns={'categroy_name' : 'category_name'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02ca63d-b819-4d23-8461-2a1f35e2dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot.to_excel('top_5k_category.xlsx' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d382b2-73c9-4ca1-b4a7-cc9f910d80fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'national_catid', 'category_name'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee232c4f-d8cb-475b-bfba-9720bc7e7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot = df_hot[['national_catid', 'category_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d1a9d8b-3725-4af7-8d46-d03683fd46e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_catid</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10050521</td>\n",
       "      <td>Body Massage Centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11010608</td>\n",
       "      <td>Massage Centres For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10272436</td>\n",
       "      <td>Interior Designers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10076456</td>\n",
       "      <td>Car Rental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10042600</td>\n",
       "      <td>Beauty Spas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_catid            category_name\n",
       "0        10050521     Body Massage Centres\n",
       "1        11010608  Massage Centres For Men\n",
       "2        10272436       Interior Designers\n",
       "3        10076456               Car Rental\n",
       "4        10042600              Beauty Spas"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838928ff-5dcf-4a1c-898c-5b2ee8a8a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 run this cell to import the library and access the gpt api\n",
    "import json\n",
    "import re\n",
    "import faiss\n",
    "import torch\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "# ----------------------- SETUP -----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e884cb-3abf-4450-8184-ea0c93f412d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 to call the gpt api\n",
    "def get_response(prompt):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": API_KEY,\n",
    "    }\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"max_tokens\": 1600\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(ENDPOINT, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "        # return response.json()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce4370f-4925-4d02-9bd0-f95ce8ae010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4 prompt 1\n",
    "def prompt1(history_conversation , original_input):\n",
    "    history_text = \"\"\n",
    "    categories = \"\"\n",
    "    \n",
    "    # Build categories string\n",
    "    for cat in df_hot['category_name']:  # <-- fixed typo here\n",
    "        categories += f\"{cat}, \"\n",
    "    \n",
    "    # Build history text\n",
    "    for i, (question, reply) in enumerate(history_conversation.items(), start=1):\n",
    "        history_text += f\"{i}. You asked: {question}\\n   User replied: {reply}\\n\"\n",
    "\n",
    "    # print(history_text)\n",
    "    prompt2 = f\"\"\"\n",
    "   You are an intelligent assistant helping Indian users find the right local service or business. Your job is to extract details from the userâ€™s query like category , area and city:\n",
    "  Input Context\n",
    "    Previous clarifications: \"{history_text}\"\n",
    "    Reference Justdial categories: \"{categories}\"\n",
    "    Extraction Priority\n",
    "    Category (Highest priority): Used Justdial categories as refrence to suggest most similar category which fulfill the user need also please ensure that suggested category should present on the justdial platform.\n",
    "    City (Second priority): Extract the Indian city where service is required.\n",
    "    Area (Third priority): Extract neighbourhood, locality, colony, or sub-part of the city.\n",
    "    - If all three details (category, area, city) are confidently identified and specific and there is no missing value and all value is filled  then only return in this format:\n",
    "      Return only this JSON format (no explanation text):\n",
    "          {{\"category\": \"category_name\", \"area\": \"area_name\", \"city\": \"city_name\"}}\n",
    "    If any detail is missing or unclear, output a direct question to get that detail.\n",
    "    If any detail is missing or unclear, do not output JSON. Instead, ask a direct clarification question such as:\n",
    "    \"Could you please specify the city where you need this service?\"\n",
    "    \"Which area in Delhi are you searching in?\"\n",
    "    \"Are you looking for a train ticket agent, bus booking, or flight booking?\"     \n",
    "    \"\"\"\n",
    "    return prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36409b35-e0da-4d8a-9074-2be0f1015b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10775 entries, 0 to 10774\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   national_catid  10775 non-null  int64 \n",
      " 1   category_name   10775 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 168.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_hot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0096fa-8f27-4f1a-8f14-0e526ad4cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 9\n",
    "def extract_json(response):\n",
    "    match = re.search(r'\\{.*?\\}', response, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group())\n",
    "        except:\n",
    "            return None\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "553963ab-37aa-4583-8229-a628325d1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # keep only letters, numbers, spaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae26dbd8-0186-44e8-a319-df8b4aa83556",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # step 11\n",
    "  not_field = {\n",
    "    \"N/A\", \"NA\", \"n/a\", \"na\", \"null\", \"NULL\", \"\", \"-\", \"none\", \"None\",\n",
    "    \"not available\", \"not applicable\", \"unspecified\", \"unknown\",\n",
    "    \"not_available\", \"not_applicable\", \"not_provided\", \"not_supplied\",\n",
    "    \"not_captured\", \"not_recorded\", \"not_collected\", \"not_entered\",\n",
    "    \"not_disclosed\", \"not_shared\", \"not_furnished\", \"not_known\",\n",
    "    \"not_identified\", \"not_determined\", \"undetermined\", \"missing\",\n",
    "    \"missing_value\", \"missing_data\", \"no_data\", \"no_response\",\n",
    "    \"no_answer\", \"no_result\", \"empty_value\", \"blank_value\",\n",
    "    \"null_value\", \"withheld\", \"redacted\", \"confidential\",\n",
    "    \"pii_removed\", \"policy_restricted\", \"compliance_restricted\",\n",
    "    \"restricted\", \"forbidden\", \"blocked\", \"safety_blocked\",\n",
    "    \"content_blocked\", \"ambiguous\", \"unclear\", \"vague\",\n",
    "    \"needs_clarification\", \"insufficient_context\", \"insufficient_detail\",\n",
    "    \"low_confidence\",\"not provided\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d9a27f4-bacb-4c77-9155-5653ea16d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_conversation1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a386f81-3d2b-4805-981b-cf3d79ad8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = prompt1(history_conversation1, 'I am looking for totels')\n",
    "response = get_response(prompt2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dbfe30e-ba95-410a-a867-3f7dbb87ffb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c88f0aca-4f09-468e-9b37-488a3d528247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'content_filter_results': {'hate': {'filtered': False,\n",
       "     'severity': 'safe'},\n",
       "    'protected_material_code': {'filtered': False, 'detected': False},\n",
       "    'protected_material_text': {'filtered': False, 'detected': False},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}},\n",
       "   'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'annotations': [],\n",
       "    'content': 'Could you please specify the city where you need this service?',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1756792683,\n",
       " 'id': 'chatcmpl-CBEJnz9TYDAg61HQOrnYvKYYWzeLt',\n",
       " 'model': 'gpt-4o-mini-2024-07-18',\n",
       " 'object': 'chat.completion',\n",
       " 'prompt_filter_results': [{'prompt_index': 0,\n",
       "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
       "    'jailbreak': {'filtered': False, 'detected': False},\n",
       "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
       "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
       "    'violence': {'filtered': False, 'severity': 'safe'}}}],\n",
       " 'system_fingerprint': 'fp_efad92c60b',\n",
       " 'usage': {'completion_tokens': 13,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens': 26427,\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0},\n",
       "  'total_tokens': 26440}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e07600-ddb4-422c-a9b1-55aa469d6e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 12\n",
    "# main function handle all conversation and follow up question\n",
    "def main_function(response, area_1=\"\", city_1=\"\" , start=False):\n",
    "    first_user = input(f\"Assitant : {response}\\nUser : \")\n",
    "    history_conversation = {}\n",
    "    a = response\n",
    "    a = a.lower()\n",
    "    if start == True:\n",
    "      first_user +=f\"area is {area_1} , and city is {city_1} Please used this only as area and city not ask the question related area and city but ask question on categories for clarity\"\n",
    "    history_conversation[a] = first_user.lower()\n",
    "    df_cat_res = pd.DataFrame()\n",
    "    df_area_res = pd.DataFrame()\n",
    "    cat = ''\n",
    "    area = ''\n",
    "    city = ''\n",
    "    cnt=0\n",
    "    # Adjusted threshold condition for better clarity\n",
    "    while (cnt < 7):\n",
    "        # Assuming prompt_fun1 generates the query for extracting data\n",
    "        prompt2 = prompt1(history_conversation, first_user)\n",
    "        response = get_response(prompt2)\n",
    "        # print(response)\n",
    "        parsed = extract_json(response)\n",
    "        if parsed:\n",
    "            cat = parsed.get(\"category\")\n",
    "            area = parsed.get(\"area\")\n",
    "            city = parsed.get(\"city\")\n",
    "\n",
    "            # If any of the parsed data is missing, skip and ask for more clarification\n",
    "            cat_clean = preprocess_text(cat)\n",
    "            area_clean = preprocess_text(area)\n",
    "            city_clean = preprocess_text(city)\n",
    "\n",
    "            # Preprocess not_field set\n",
    "            not_field_clean = {preprocess_text(x) for x in not_field}\n",
    "\n",
    "            # Now check\n",
    "            if (not cat_clean or cat_clean in not_field_clean or\n",
    "                not area_clean or area_clean in not_field_clean or\n",
    "                not city_clean or city_clean in not_field_clean):\n",
    "\n",
    "                missing_data = []\n",
    "                if not cat_clean or cat_clean in not_field_clean:\n",
    "                    missing_data.append(\"Category\")\n",
    "                if not area_clean or area_clean in not_field_clean:\n",
    "                    missing_data.append(\"Area\")\n",
    "                if not city_clean or city_clean in not_field_clean:\n",
    "                    missing_data.append(\"City\")\n",
    "                missing_str = ', '.join(missing_data)\n",
    "                response = f\"We are unable to get your {missing_str}, Please specify it with city.\"\n",
    "                user_input = input(f\"Assitant : {response}\\nUser : \")\n",
    "                history_conversation[response] = user_input\n",
    "                cnt += 1\n",
    "                continue   # Re-run the loop for further input            \n",
    "            print(f\"Gpt Extracted:\\nCategory: {cat}\\nArea: {area}\\nCity: {city}\")\n",
    "            return cat , area , city\n",
    "        else :\n",
    "            user = input(f\"Assitant : {response}\\nUser : \")\n",
    "            history_conversation[response] = user\n",
    "            cnt+=1\n",
    "    print(f\"Gpt Extracted:\\nCategory: {cat}\\nArea: {area}\\nCity: {city}\")\n",
    "    return cat , area , city\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea6c4b5d-c503-48f2-a14f-d50ff950d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 14\n",
    "# This final function which handle the starting and ending of conversation\n",
    "def whatshapp_chat():\n",
    "  end = False\n",
    "  response = 'How can I help you ?'\n",
    "  area = ''\n",
    "  city = ''\n",
    "  start=False\n",
    "  while end!=True:\n",
    "    try:\n",
    "      cat_name, main_area , city = main_function(response , area , city , start)\n",
    "      start = True\n",
    "      temp = input(f\"Do you want to end the conversation ? (yes/no): \\n\").lower()\n",
    "      if temp == \"yes\":\n",
    "        end = True\n",
    "        break\n",
    "    except Exception as e:\n",
    "      print(f\"An error occurred: {e}\")\n",
    "      end = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "760a22ce-ba6e-4a44-9ba0-0c3e9629d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant : How can I help you ?\n",
      "User :   my sister getting married khana bhanana ke liya chahiye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: expected string or bytes-like object, got 'dict'\n"
     ]
    }
   ],
   "source": [
    "whatshapp_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f473a5c6-c836-43f0-a40a-8bc3511717a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assitant : How can I help you ?\n",
      "User :  my sister getting married khana bhanana ke liya chahiye\n",
      "Assitant : Could you please specify the city where you need this service?\n",
      "User :  bangalore\n",
      "Assitant : Could you please specify the area in Bangalore where you need this catering service?\n",
      "User :  peenya\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m whatshapp_chat()\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mwhatshapp_chat\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m end\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     cat_name, main_area , city \u001b[38;5;241m=\u001b[39m main_function(response , area , city , start)\n\u001b[0;32m     12\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     temp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo you want to end the conversation ? (yes/no): \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower()\n",
      "Cell \u001b[1;32mIn[16], line 58\u001b[0m, in \u001b[0;36mmain_function\u001b[1;34m(response, area_1, city_1, start)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cat , area , city\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m---> 58\u001b[0m     user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssitant : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mUser : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m     history_conversation[response] \u001b[38;5;241m=\u001b[39m user\n\u001b[0;32m     60\u001b[0m     cnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "whatshapp_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859ed12-ae93-4bf8-848a-5b68895e31b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
